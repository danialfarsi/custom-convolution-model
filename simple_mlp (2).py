# -*- coding: utf-8 -*-
"""Simple_MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b53LOjmREJml5yrAc5O06JM-KLVxol66
"""

import torch;
import torchvision;
from torchvision import transforms;
import torch.nn as nn

batch_size = 64
n_class = 10
lr = 0.001
num_epochs = 10

train_dataset = torchvision.datasets.MNIST(root="./Dataset",train=True , transform=transforms.ToTensor(),
                                           download = True)

test_dataset = torchvision.datasets.MNIST(root="./Dataset",train=False , transform=transforms.ToTensor(),
                                           download = True)


train_loader = torch.utils.data.DataLoader(dataset=train_dataset , batch_size = 64 , shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset , batch_size = 64 , shuffle=True)
n_class = 64

class convnet(nn.Module):
    def __init__(self):
        super(convnet,self).__init__()
        self.layer1 = nn.Sequential(nn.Conv2d(1, 16, 3, 1, 2),
                                    nn.BatchNorm2d(16),
                                    nn.ReLU(),
                                    nn.MaxPool2d(2, 2))
        self.layer2 = nn.Sequential(nn.Conv2d(16, 32, 3, 1, 2),
                                    nn.BatchNorm2d(32),
                                    nn.ReLU(),
                                    nn.MaxPool2d(2, 2))
        self.fc = nn.Linear(8*8*32, n_class)
    def forward(self,x):
      out1 = self.layer1(x)
      out2 = self.layer2(out1)
      out2 = out2.reshape(out2.size(0), -1)
      main   = self.fc(out2)

      return main

model = convnet()

loss_func = nn.CrossEntropyLoss()

opt = torch.optim.SGD(model.parameters() , lr=lr)

num_step = len(train_loader)
for i in range(num_epochs):
  for j , (img,label) in enumerate(train_loader):
    out = model(img)
    loss_value = loss_func(out,label)
    opt.zero_grad()
    loss_value.backward()
    opt.step()
    if(j+1)%100 == 0:
     print("Epoch [{},{}] step [{},{}] Loss:{:.4f}".format(i+1,num_epochs,j+1 , num_step , loss_value.item()))
true = 0
model.eval()
corrects = 0
num_steps = len(test_loader)
for j , (img,label) in enumerate(test_loader):
  out = model(img)
  predict = torch.argmax(out , 1)
  true += torch.sum(predict == label);
  print("Step [{},{}] Acc{:.4f}:".format(j+1 , num_steps , 100.*true/((j+1)*batch_size)))

print(test_loader)